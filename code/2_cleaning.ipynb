{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Load in all the recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.json',\n",
       " '001.json',\n",
       " '002.json',\n",
       " '004.json',\n",
       " '005.json',\n",
       " '006.json',\n",
       " '007.json',\n",
       " '008.json',\n",
       " '009.json',\n",
       " '010.json',\n",
       " '011.json',\n",
       " '012.json',\n",
       " '013.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the folder, remove the checkpoints file\n",
    "os.listdir('../data/api_data/')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all json as dataframes\n",
    "list_of_dfs = []\n",
    "for file in os.listdir('../data/api_data/')[1:]:\n",
    "    with open(f'../data/api_data/{file}') as f:\n",
    "        list_of_dfs.append(pd.DataFrame(json.load(f)['recipes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 38)\n",
      "(54, 37)\n",
      "(50, 37)\n",
      "(100, 37)\n",
      "(100, 37)\n",
      "(100, 37)\n",
      "(100, 37)\n",
      "(100, 38)\n",
      "(100, 37)\n",
      "(100, 38)\n",
      "(100, 37)\n",
      "(100, 37)\n",
      "(100, 37)\n"
     ]
    }
   ],
   "source": [
    "for dframe in list_of_dfs:\n",
    "    print(dframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Merge all the dataframes into one, dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = list_of_dfs[0]\n",
    "\n",
    "for dframe in list_of_dfs[1:]:\n",
    "    master_df = master_df.append(dframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random recipes were acquired using the api\n",
    "# drop duplicates\n",
    "master_df = master_df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692, 38)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### A bit of feature selection to make the dataframe a bit smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vegetarian', 'vegan', 'glutenFree', 'dairyFree', 'veryHealthy',\n",
       "       'cheap', 'veryPopular', 'sustainable', 'weightWatcherSmartPoints',\n",
       "       'gaps', 'lowFodmap', 'aggregateLikes', 'spoonacularScore',\n",
       "       'healthScore', 'creditsText', 'license', 'sourceName',\n",
       "       'pricePerServing', 'extendedIngredients', 'id', 'title',\n",
       "       'readyInMinutes', 'servings', 'sourceUrl', 'image', 'imageType',\n",
       "       'summary', 'cuisines', 'dishTypes', 'diets', 'occasions',\n",
       "       'instructions', 'analyzedInstructions', 'originalId',\n",
       "       'spoonacularSourceUrl', 'preparationMinutes', 'cookingMinutes',\n",
       "       'author'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While some models may drop further features, these are the ones I don't plan on using at all\n",
    "features_to_drop = [\n",
    "    'weightWatcherSmartPoints',\n",
    "    'gaps',\n",
    "    'veryPopular',\n",
    "    'aggregateLikes',\n",
    "    'spoonacularScore',\n",
    "    'healthScore',\n",
    "    'creditsText',\n",
    "    'license',\n",
    "    'sourceName',\n",
    "    'pricePerServing',\n",
    "    'id',\n",
    "    'servings',\n",
    "    'sourceUrl',\n",
    "    'image',\n",
    "    'imageType',\n",
    "    'diets',\n",
    "    'originalId',\n",
    "    'spoonacularSourceUrl',\n",
    "    'cookingMinutes',\n",
    "    'preparationMinutes',\n",
    "    'author'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the features\n",
    "master_df = master_df.drop(columns=features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "analyzedInstructions    0\n",
       "lowFodmap               0\n",
       "vegan                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the columns had the added benefit of clearing all of the missing values\n",
    "# one thing to note however is that some of the columns have an empty list instead of nan\n",
    "# those were not removed\n",
    "master_df.isnull().sum().sort_values(ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned recipes as a csv\n",
    "master_df.to_csv('../data/recipes.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
